\subsection{%
  Лекция \texttt{24.??.??}.%
}

\subheader{Критерии для проверки гипотез о распределении}

\subsubheader{I.}{Критерий \(\chi^2\) (для проверки параметрической гипотезы)}

Пусть дана выборка \(\sample{X} = \prh{X_1, \dotsc, X_n}\) неизвестного
распределения \(\mathcal{F}\). Проверяется основная (сложная) гипотеза \(H_0\) о
том, что \(\mathcal{F} \in \mathcal{F}_{\Theta}\), где \(\mathcal{F}_{\Theta}\)
это распределение известного типа, определяемое набором из \(m\) неизвестных
параметров \(\Theta = \prh{\Theta_1, \dotsc, \Theta_m}\). В качестве
альтернативной гипотезы \(H_1\) о том, что \(\mathcal{F} \notin
\mathcal{F}_{\Theta}\).

Пусть \(\widehat{\Theta} = \prh{\widehat{\Theta}_1, \dotsc,
\widehat{\Theta}_m}\)~--- оценка неизвестных параметров \(\Theta =
\prh{\Theta_1, \dotsc, \Theta_m}\) методом максимального правдоподобия. Разобьем
выборку на \(k\) интервалов \(A_i = [a_i; a_{i + 1})\), обозначим \(n_i\)
соответствующие частоты этих интервалов. Пусть \(p_i = F_{\widehat{\Theta}}
(a_{i + 1}) - F_{\widehat{\Theta}} (a_i)\) это теоретические вероятности
попадания случайной величины с распределением \(\mathcal{F}_{\widehat{\Theta}}\)
в данные интервалы. Тогда \(n' = n p_i\) это теоретические частоты в эти
интервалы.

В качестве статистики критерия берется функция

\begin{equation*}
  K
  = \sum_{i = 1}^k \frac{\prh{n_i - n'_i}^2}{n'_i}
  = \sum_{i = 1}^k \frac{n_i^2}{n'_i} - n
\end{equation*}

\begin{theorem}[Фишера]
  Если гипотеза \(H_0 \colon \mathcal{F} \in \mathcal{F}_{\Theta}\) верна, то

  \begin{equation*}
    K = \sum_{i = 1}^k \frac{\prh{n_i - n'_i}^2}{n'_i}
    \rightrightarrows
    \chi_{k - m - 1}^2
  \end{equation*}

  где \(k\) это число интервалов, \(m\)~--- число параметров распределения.
\end{theorem}

Получили следующий критерий: для заданного уровня значимости \(\alpha\) находим
\(\tcrit\) такое, что \(\display{\prob{\chi_{k - m - 1}^2 \ge \tcrit} =
\alpha}\). Тогда критерий согласия имеет вид

\begin{equation*}
  \begin{cases}
    H_0, & K < \tcrit \\
    H_1, & K \ge \tcrit
  \end{cases}
\end{equation*}

\begin{remark}
  Для вычисления квантиля можно использовать формулу Excel \texttt{ХИ2.ОБР.ПХ
  \((\alpha, k - m - 1)\)}.
\end{remark}

\begin{remark}
  Частота каждого интервала должна быть не менее пяти. Если это не так, то
  сливаем соседние интервалы. Число интервалов желательно брать достаточно
  большим (чтобы \(k - m - 1\) было больше), но при этом стоит помнить об
  ограничениях на частоту каждого интервала.
\end{remark}

\begin{remark}
  При этом критерии выборку лучше разбивать на \quote{равнонаполненные}
  интервалы, т.е. на интервалы содержащие примерно одинаковое число элементов
  выборки.
\end{remark}

\begin{remark}
  Желательно, чтобы объем выборки был не менее \(50\). В противном случае метод
  работает плохо.
\end{remark}

\spreadsheet{01_07_01}{0.97 \linewidth}{X|X|X|X|X|X|X|X|X|X}
  {Интервальный ряд для примера \ref{ex:interval-row}}{ex-interval-row}

\begin{example} \label{ex:interval-row}
  Имеется выборка в виде вариационного ряда \(\sample{X} = \prh{5.2, \dotsc,
  22.8}\) объема \(n = 120\). При разбиении ее на \(k = 8\) интервалов
  одинаковой длины получили интервальный ряд \ref{tbl:ex-interval-row}.
  Проверить гипотезу о равномерности этого распределения при уровне значимости
  \(\alpha = 0.05\).

  \solution{} Итак, проверяем гипотезу \(H_0 \colon \mathcal{F} \in
  \udist{a}{b}\) против альтернативной \(H_1 \colon \mathcal{F} \notin
  \udist{a}{b}\). По методу наибольшего правдоподобия получаем (смещенные)
  оценки \(a^* = 5.2\) и \(b^* = 22.8\). Теоретические вероятности случайной
  величины с распределением \(\udist{5.2}{22.8}\) равны \(p_i = \frac{1}{k} =
  \frac{1}{8}\). Тогда теоретические частоты \(n'_i = n p_i = 15\). Далее
  вычисляем статистику

  \begin{equation*}
    \chi^2_{\text{набл}}
    = \sum_{i = 1}^k \frac{\prh{n_i - n'_i}^2}{n'_i}
    = 3.2
  \end{equation*}

  При уровне значимости \(\alpha = 0.05\) и числе степеней свободы \(k - m - 1 =
  5\) находим \texttt{\(\tcrit =\) ХИ2.ОБР.ПХ \((0.05, 5) = 11.07\)}. Таким
  образом, т.к. \(\chi_{\text{набл}} < \tcrit\), то принимаем основную гипотезу
  о равномерном распределении.
\end{example}

\subsubheader{II.}{Критерий \(\chi^2\)}

Постановка задачи отличается от предыдущего пункта тем, что проверяется
простая основная гипотеза \(H_0\) о том, что \(\mathcal{F} = \mathcal{F}_1\),
где \(\mathcal{F}_1\) это распределение известного типа с известными
параметрами. В качестве статистики берем ту же функцию

\begin{equation*}
  K = \sum_{i = 1}^k \frac{\prh{n_i - n'_i}^2}{n'_i}
\end{equation*}

\begin{theorem}[Пирсона]
  Если \(H_0 \colon \mathcal{F} = \mathcal{F}_1\) верна, то

  \begin{equation*}
    K = \sum_{i = 1}^k \frac{\prh{n_i - n'_i}^2}{n'_i}
    \rightrightarrows \chi_{k - 1}^2
  \end{equation*}
\end{theorem}

В остальном критерий аналогичен предыдущему.

\subsubheader{III.}{Критерий Колмогорова}

Пусть имеется выборка \(\sample{X} = \prh{X_1, \dotsc, X_n}\) объема \(n\)
распределения \(\mathcal{F}\). Проверяется нулевая гипотеза \(H_0 \colon
\mathcal{F} = \mathcal{F}_1\) против альтернативной \(H_1 \colon \mathcal{F}
\neq \mathcal{F}_1\), где \(\mathcal{F}_1\) это абсолютно непрерывное
распределение известного типа с известными параметрами. Обозначим \(F(x)\)~---
функцию распределения \(\mathcal{F}_1\), а \(F^* (x)\)~--- выборочную функцию
распределения.

\begin{theorem}[Колмогорова]
  Если гипотеза \(H_0 \colon \mathcal{F} = \mathcal{F}_1\) верна, то

  \begin{equation*}
    K = \sqrt{n} \cdot \sup_x \abs{F(x) - F^* (x)}
    \rightrightarrows
    \mathcal{K}
  \end{equation*}

  где \(\mathcal{K}\) это распределение Колмогорова с функцией распределения

  \begin{equation*}
    F_{\mathcal{K}} (x)
    = \sum_{j = -\infty}^{\infty} (-1)^j \exp \prh{-2 j^2 x^2}
  \end{equation*}
\end{theorem}

В результате получаем критерий Колмогорова: пусть \(\tcrit\) это квантиль
распределения Колмогорова уровня значимости \(\alpha\), тогда

\begin{equation*}
  \begin{cases}
    H_0, & K < \tcrit \\
    H_1, & K \ge \tcrit
  \end{cases}
\end{equation*}

\subheader{Критерии для проверки однородности}

\subsubheader{IV.}{Критерий Колмогорова---Смирнова}

Пусть имеются две независимые выборки \(\sample{X} = \prh{X_1, \dotsc, X_n}\) и
\(\sample{Y} = \prh{Y_1, \dotsc, Y_m}\) неизвестных непрерывных распределений
\(\mathcal{F}\) и \(\mathcal{J}\). Проверяется основная гипотеза \(H_0\) о том,
что \(\mathcal{F} = \mathcal{J}\) против альтернативной \(H_1\) о том, что
\(\mathcal{F} \neq \mathcal{J}\). В качестве статистики критерия берется функция

\begin{equation*}
  K = \sqrt{\frac{n m}{n + m}} \cdot
    \sup_x \abs{\mathcal{F}^* (x) - \mathcal{J}^* (x)}
\end{equation*}

где \(\mathcal{F}^* (x)\) и \(\mathcal{J}^* (x)\) это соответствующие выборочные
функции распределения.

\begin{theorem}[Колмогорова---Смирнова]
  Если гипотеза \(H_0 \colon \mathcal{F} = \mathcal{J}\) верна, то \(\display{K
  \rightrightarrows \mathcal{K}}\).
\end{theorem}

В результате получаем критерий Колмогорова---Смирнова: пусть \(\tcrit\) это
квантиль распределения Колмогорова уровня значимости \(\alpha\), тогда

\begin{equation*}
  \begin{cases}
    H_0, & K < \tcrit \\
    H_1, & K \ge \tcrit
  \end{cases}
\end{equation*}

\begin{remark}
  Этот критерий не часто используют. Основные критерии это критерии Фишера и
  Стьюдента (они описаны ниже). Сначала применяется критерий Фишера, и если он
  не отвергает основную гипотезу, применяется критерий Стьюдента.
\end{remark}

\subsubheader{V.}{Критерий Фишера}

Пусть имеются две независимые выборки \(\sample{X} = \prh{X_1, \dotsc, X_n}\) и
\(\sample{Y} = \prh{Y_1, \dotsc, Y_m}\) нормальных распределений \(X \in
\ndist{a_1}{\sigma_1^2}\) и \(Y \in \ndist{a_2}{\sigma_2^2}\). Проверяется
основная гипотеза \(H_0\) о том, то \(\sigma_1 = \sigma_2\) против
альтернативной \(H_1\) о том, то \(\sigma_1 \neq \sigma_2\). В качестве
статистики критерия берется функция

\begin{equation*}
  K = \frac{S_x^2}{S_y^2}
\end{equation*}

где \(S_x^2\) и \(S_y^2\)~--- соответствующие исправленные выборочные дисперсии,
причем \(S_x^2 \ge S_y^2\).

\begin{theorem}
  Если гипотеза \(H_0 \colon \sigma_1 = \sigma_2\) верна, то \(K \in \Fdist{n -
  1}{m - 1}\).
\end{theorem}

\begin{proof}
  Если \(H_0\) верна, то \(\sigma_1 = \sigma_2\), поэтому

  \begin{equation*}
    K
    = \frac{S_x^2}{S_y^2}
    = \frac{S_x^2}{\sigma_1^2} \cdot \frac{\sigma_2^2}{S_y^2}
  \end{equation*}

  По \ref{lem:base-theorem-3} получаем, что

  \begin{equation*}
    \frac{(n - 1) S^2}{\sigma^2}
    \in \Hdist{n - 1}
    \implies
    K = \frac{\chi_{n - 1}^2}{n - 1} \cdot \frac{m - 1}{\chi_{m - 1}^2}
    \in \Fdist{n - 1}{m - 1}
    \text{ по определению}
  \end{equation*}
\end{proof}

Получили критерий: пусть \(\tcrit\) это квантиль распределения \(\Fdist{n
- 1}{m - 1}\) уровня значимости \(\alpha\), тогда

\begin{equation*}
  \begin{cases}
    H_0, & K < \tcrit \\
    H_1, & K \ge \tcrit
  \end{cases}
\end{equation*}

\begin{remark}
  Если гипотеза неверна, то статистика \(K\) стремится не к бесконечности, а к
  \(\frac{\sigma_1^2}{\sigma_2^2}\).
\end{remark}

\subsubheader{VI.}{Критерий Стьюдента}

Пусть имеются две независимые выборки \(\sample{X} = \prh{X_1, \dotsc, X_n}\) и
\(\sample{Y} = \prh{Y_1, \dotsc, Y_m}\) нормальных распределений \(X \in
\ndist{a_1}{\sigma^2}\) и \(Y \in \ndist{a_2}{\sigma^2}\) с одинаковой
дисперсией \(\sigma^2\). Проверяется основная гипотеза \(H_0\) о том, то \(a_1 =
a_2\) против альтернативной \(H_1\) о том, то \(a_1 \neq a_2\). В качестве
статистики критерия берется функция

\begin{equation*}
  K = \sqrt{\frac{n m}{n + m}} \cdot \frac{\avg{x} - \avg{y}}
    {\sqrt{\frac{(n - 1) S_x^2 + (m - 1) S_y^2}{n + m - 2}}}
\end{equation*}

\begin{theorem}
  \begin{equation*}
    \sqrt{\frac{n m}{n + m}} \cdot \frac{(\avg{x} - a_1) - (\avg{y} - a_2)}
      {\sqrt{\frac{(n - 1) S_x^2 + (m - 1) S_y^2}{n + m - 2}}}
    \in \Tdist{n + m - 2}
  \end{equation*}
\end{theorem}

Из этой теоремы следует, что если гипотеза \(H_0\) верна, то \(K \in \Tdist{n +
m - 2}\). А если она не верна, то \(\abs{K} \to \infty\). Получаем критерий:
пусть \(\tcrit\) это квантиль распределения \(\abs{\Tdist{n + m - 2}}\)
уровня значимости \(\alpha\), тогда

\begin{equation*}
  \begin{cases}
    H_0, & \abs{K} < \tcrit \\
    H_1, & \abs{K} \ge \tcrit
  \end{cases}
\end{equation*}

\subheader{Критерий вероятности появления события}

Пусть \(\prob{A} = p\)~--- неизвестная теоретическая вероятность события \(A\).
При достаточно большом числе \(n\) независимых испытаний события \(A\) появилось
\(m\) раз. Проверяется основная гипотеза \(H_0\) о том, что \(\prob{A} = p_0\)
против альтернативной \(H_1\) о том, что \(\prob{A} \neq p_0\). Обозначим \(p^*
= \frac{m}{n}\) точечную оценку \(\prob{A}\). В качестве статистики критерия
берем величину

\begin{equation*}
  K = \frac{m - n p_0}{\sqrt{n p_0 q_0}}
  \qquad
  (q_0 = 1 - p_0)
\end{equation*}

Если \(H_0\) верна, то \(K = \frac{m - n p}{\sqrt{n p q}} \rightrightarrows
\ndist{0}{1}\) согласно теореме Муавра---Лапласа. Получаем критерий: пусть
\(\tcrit\) это точка такая, что \(\Phi \prh{\tcrit} = \frac{1 - \alpha}{2}\),
где \(\alpha\) это уровень значимости. Тогда

\begin{equation*}
  \begin{cases}
    H_0, & \abs{K} < \tcrit \\
    H_1, & \abs{K} \ge \tcrit
  \end{cases}
\end{equation*}

\begin{example}
  При посеве гороха вероятность рецессивного признака \(p = 0.25\), а
  доминантного~--- \(q = 0.75\). Из \(n = 4000\) посеянных семян \(970\)
  оказались с рецессивным признаком, а \(3030\)~--- с доминантным. Проверяется
  основная гипотеза \(H_0\) о том, что \(p = 0.25\), против альтернативной
  \(H_1\) о том, что \(p \neq 0.25\).

  \solution{} Вычисляем статистику

  \begin{equation*}
    K = \frac{m - n p_0}{\sqrt{n p_0 q_0}} = -1.095 
  \end{equation*}

  Далее найдем \(\tcrit\).

  \begin{equation*}
    \Phi \prh{\tcrit}
    = \frac{1 - 0.05}{2}
    = 0.475
    \implies
    \tcrit = 1.96
  \end{equation*}

  Т.к. \(\abs{K} < \tcrit\), то гипотеза \(H_0\) принимается.
\end{example}
