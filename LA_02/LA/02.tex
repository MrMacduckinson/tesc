\question{Ортонормированный базис, ортогонализация базиса. Матрица Грама.}

\begin{definition}
  \textit{Уголом} между двумя элементами Евклидова пространства называется
  \begin{lequation}{angle-def}
    \cos \angle (x, y) = \frac{(x, y)}{\norm{x} \cdot \norm{y}}
  \end{lequation}
\end{definition}

\begin{definition}
  Для элемента Евклидова пространства ортогональны, если их скалярное
  произведение равно нулю.
  \begin{lequation}{ort-def}
    x \bot y \iff (x, y) = 0
  \end{lequation}
\end{definition}

\begin{theorem}
  Во всяком \(E^{n}\) можно выделить ортонормированный базис размера \(n\).
\end{theorem}
\begin{proof}
  Пусть у нас есть базис \(B = \{ \beta_{1}, \dotsc, \beta_{n} \}\).
  Ортогонализируем его, полученный базис обозначим
  \(E' = \{ e'_{1}, \dotsc, e'_{n} \}\). Этот базис можно нормировать и получить
  искомый ортонормированный базис \(E = \{ e_{1}, \dotsc, e_{n} \}\).

  \textbf{Процесс ортогонализации Грама-Шмидта:}

  Будем добавлять векторы в базис \(E\) из базиса \(B\) по-одному:

  \textbf{База:} начнем с одного произвольного вектора \(\beta_1\).
  Тогда \(e'_{1} = \beta_{1}\).

  \textbf{Переход:} пусть у нас уже выделен набор из \(k - 1\) ортогональных
  векторов \(\{ e'_{1}, \dotsc, e'_{k - 1} \}\) и в него требуется добавить
  вектор \(\beta_{k}\).

  Будем искать \(e'_{k}\) в виде

  \begin{lequation}{ort-basic-proof-1}
    e'_{k}
      = \beta_{k}
      + \lambda_{1} e'_{k - 1}
      + \lambda_{2} e'_{k - 2}
      + \dotsc
      + \lambda_{k - 1} e'_{1}
  \end{lequation}

  Чтобы \(e'_{k}\) был ортогонален остальным векторам уже построенной системы,
  необходимо, чтобы скалярные произведение \(e'_{k}\) с остальными векторами
  системы равнялись нулю. Рассмотрим на примере \(e'_{1}\):

  \begin{lequation}{ort-basic-proof-2}
    (e'_{k}, e'_{1})
      = (\beta_{k}, e'_{1})
      + \lambda_{1} (e'_{k - 1}, e'_{1})
      + \dotsc
      + \lambda_{k - 1} (e'_{1}, e'_{1})
      = 0
  \end{lequation}

  Учитывая то, что построенная система ортогональна, то
  \((e'_{i}, e'_{j}) = 0 \; (i, j < k)\). Значит выражение выше упрощается и
  остается:

  \begin{lequation}{ort-basic-proof-3}
     (\beta_{k}, e'_{1})  + \lambda_{k - 1} (e'_{1}, e'_{1}) = 0 \\
     \lambda_{k - 1} = -\frac{(\beta_{k}, e'_{1})}{(e'_{1}, e'_{1})}
  \end{lequation}

  Аналогично можно получить оставшиеся коэффициенты \(\lambda_{i}\). Тогда
  добавляемый в систему вектор \(e'_{k}\) будет иметь вид:

  \begin{lequation}{ort-basic-proof-4}
    e'_{k}
    = \beta_{k}
    - \frac{(\beta_{k}, e'_{k - 1})}{(e'_{k - 1}, e'_{k - 1})} \cdot e'_{k - 1}
    - \frac{(\beta_{k}, e'_{k - 2})}{(e'_{k - 2}, e'_{k - 2})} \cdot e'_{k - 2}
    - \dotsc
    - \frac{(\beta_{k}, e'_{1})}{(e'_{1}, e'_{1})} \cdot e'_{1}
  \end{lequation}
\end{proof}

\begin{definition}
  Матрицей Грама называется матрица составленная из скалярных произведений

  \begin{lequation}{G-mtx}
    \begin{pmatrix}
      (e_{1}, e_{1}) & \dots  & (e_{k}, e_{1}) \\
      \vdots         & \ddots & \vdots \\
      (e_{1}, e_{k}) & \dots  & (e_{k}, e_{k}) \\
    \end{pmatrix}
  \end{lequation}
\end{definition}

\begin{remark}
  В ортогональном базисе матрица Грама диагональная, а в ортонормированном~---
  единичная.
\end{remark}
